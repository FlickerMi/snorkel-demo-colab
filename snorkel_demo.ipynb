{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snorkel-demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fastforwardlabs/snorkel-demo-colab/blob/master/snorkel_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2hgkWoEUODX",
        "colab_type": "text"
      },
      "source": [
        "# Training a text classification model using noisy regular expressions\n",
        "\n",
        "In this notebook we will walk through a simple text classification problem that trains a complaint classifier using data from [Consumer Financial Protection Bureau](https://www.consumerfinance.gov/data-research/consumer-complaints/), showing how to use Snorkel for weak supervision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaf5CrXPsVOI",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n13vH4IdX2N5",
        "colab_type": "text"
      },
      "source": [
        "Installing Snorkel and other required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q40cmhf21u79",
        "colab_type": "code",
        "outputId": "74e8b60f-30cb-44fa-b051-301aa6960688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install -r requirements.txt\n",
        "!pip3 install git+https://github.com/nishamuktewar/snorkel\n",
        "!pip3 install treedlib\n",
        "!pip3 install numbskull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4==4.7.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (4.7.1)\n",
            "Requirement already satisfied: future==0.17.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.17.1)\n",
            "Requirement already satisfied: ipywidgets==7.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (7.4.2)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.0.0)\n",
            "Requirement already satisfied: lxml==4.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: matplotlib==3.0.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (3.0.1)\n",
            "Requirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
            "Requirement already satisfied: numba==0.43.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.43.1)\n",
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (1.16.1)\n",
            "Requirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.24.2)\n",
            "Requirement already satisfied: py4j==0.10.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.10.8.1)\n",
            "Requirement already satisfied: requests==2.22.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (2.22.0)\n",
            "Requirement already satisfied: runipy==0.1.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 13)) (0.1.5)\n",
            "Requirement already satisfied: scipy==1.2.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 14)) (1.2.1)\n",
            "Requirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (1.12.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (2.1.4)\n",
            "Requirement already satisfied: sqlalchemy==1.3.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 17)) (1.3.3)\n",
            "Requirement already satisfied: tika==1.19 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 18)) (1.19)\n",
            "Requirement already satisfied: tqdm==4.32.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 19)) (4.32.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (0.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.6/dist-packages (from beautifulsoup4==4.7.1->-r requirements.txt (line 1)) (1.9.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.6.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.3.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (4.5.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (5.5.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (6.0.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (5.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: llvmlite>=0.28.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba==0.43.1->-r requirements.txt (line 8)) (0.29.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->-r requirements.txt (line 10)) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: Pygments>=1.6 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (2.1.3)\n",
            "Requirement already satisfied: pyzmq>=14.1.0 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (17.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (2.10.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.2.2)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.6.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (7.0.4)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.0.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tika==1.19->-r requirements.txt (line 18)) (41.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 20)) (0.21.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (1.0.16)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.7.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.5.3)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (5.2.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 4)) (0.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7.2->runipy==0.1.5->-r requirements.txt (line 13)) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 20)) (0.13.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Collecting git+https://github.com/nishamuktewar/snorkel\n",
            "  Cloning https://github.com/nishamuktewar/snorkel to /tmp/pip-req-build-kw_k7ya5\n",
            "  Running command git clone -q https://github.com/nishamuktewar/snorkel /tmp/pip-req-build-kw_k7ya5\n",
            "Requirement already satisfied (use --upgrade to upgrade): snorkel==0.7.0b0 from git+https://github.com/nishamuktewar/snorkel in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: snorkel\n",
            "  Building wheel for snorkel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3ysygkz3/wheels/1c/dc/7b/9cf55b0576fad8e74e4e4c004231d1fd2814b01915d5582ba2\n",
            "Successfully built snorkel\n",
            "Requirement already satisfied: treedlib in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from treedlib) (4.3.3)\n",
            "Requirement already satisfied: numbskull in /usr/local/lib/python3.6/dist-packages (0.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from numbskull) (0.17.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyPnpQ6t1-D-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNCpKXv1uwfz",
        "colab_type": "text"
      },
      "source": [
        "Disabling warning messages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf-MTJzpuTpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ongFEcu9YhSC",
        "colab_type": "text"
      },
      "source": [
        "Loading necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnphVByC2D4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import sklearn\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from snorkel import SnorkelSession\n",
        "from snorkel.models import candidate_subclass, Context, Candidate, StableLabel\n",
        "from snorkel.contrib.models.text import RawText\n",
        "from snorkel.annotations import LabelAnnotator\n",
        "from snorkel.learning import GenerativeModel\n",
        "from snorkel.annotations import save_marginals\n",
        "from snorkel.learning.tensorflow import TextRNN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2zUynbBUfV0",
        "colab_type": "text"
      },
      "source": [
        "## Download data, if it doesn't *exist*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1TWYOoI2Tnj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = \"./data\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "    !curl https://data.consumerfinance.gov/api/views/s6ew-h6mp/rows.csv?accessType=DOWNLOAD > ./data/complaints.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS5CHRYDUmfW",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "Data load, filtering out irrelevant fields and rows. Each row in the final dataframe - complaints_df,  consists of a \"complaint\" field and an associated ground truth label = (1, -1). These ground truth labels are only used to review the performance of the labeling process, afterall the whole idea is to do without any labeled data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7govEII2gM3",
        "colab_type": "code",
        "outputId": "95446b2e-1e11-4ac6-ee2f-14a258704048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "complaints = pd.read_csv(os.path.join(data_dir,'complaints.csv'))\n",
        "complaints.info()\n",
        "complaints.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,11,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1310319 entries, 0 to 1310318\n",
            "Data columns (total 18 columns):\n",
            "Date received                   1310319 non-null object\n",
            "Product                         1310319 non-null object\n",
            "Sub-product                     1075153 non-null object\n",
            "Issue                           1310319 non-null object\n",
            "Sub-issue                       775697 non-null object\n",
            "Consumer complaint narrative    387602 non-null object\n",
            "Company public response         464273 non-null object\n",
            "Company                         1310319 non-null object\n",
            "State                           1289899 non-null object\n",
            "ZIP code                        1191116 non-null object\n",
            "Tags                            179317 non-null object\n",
            "Consumer consent provided?      706068 non-null object\n",
            "Submitted via                   1310319 non-null object\n",
            "Date sent to company            1310319 non-null object\n",
            "Company response to consumer    1310312 non-null object\n",
            "Timely response?                1310319 non-null object\n",
            "Consumer disputed?              768501 non-null object\n",
            "Complaint ID                    1310319 non-null int64\n",
            "dtypes: int64(1), object(17)\n",
            "memory usage: 179.9+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1310319, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gwjyL9jUz48",
        "colab_type": "text"
      },
      "source": [
        "### Subset data to include products with narrative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BcTLpTu2iV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "products_w_narrative = complaints[complaints['Product'].notnull() & \n",
        "                                  complaints['Consumer complaint narrative'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aswvj9bu2mJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "830a5c95-4077-439f-bce6-9e82db63f575"
      },
      "source": [
        "print(products_w_narrative['Product'].unique())\n",
        "print(products_w_narrative['Product'].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Debt collection'\n",
            " 'Credit reporting, credit repair services, or other personal consumer reports'\n",
            " 'Student loan' 'Credit card or prepaid card' 'Mortgage'\n",
            " 'Money transfer, virtual currency, or money service'\n",
            " 'Payday loan, title loan, or personal loan' 'Checking or savings account'\n",
            " 'Vehicle loan or lease' 'Credit card' 'Bank account or service'\n",
            " 'Credit reporting' 'Consumer Loan' 'Prepaid card' 'Payday loan'\n",
            " 'Money transfers' 'Other financial service' 'Virtual currency']\n",
            "Credit reporting, credit repair services, or other personal consumer reports    94174\n",
            "Debt collection                                                                 87506\n",
            "Mortgage                                                                        53334\n",
            "Credit reporting                                                                31588\n",
            "Student loan                                                                    21990\n",
            "Credit card or prepaid card                                                     21787\n",
            "Credit card                                                                     18838\n",
            "Bank account or service                                                         14885\n",
            "Checking or savings account                                                     13132\n",
            "Consumer Loan                                                                    9474\n",
            "Vehicle loan or lease                                                            5833\n",
            "Money transfer, virtual currency, or money service                               5555\n",
            "Payday loan, title loan, or personal loan                                        4504\n",
            "Payday loan                                                                      1747\n",
            "Money transfers                                                                  1497\n",
            "Prepaid card                                                                     1450\n",
            "Other financial service                                                           292\n",
            "Virtual currency                                                                   16\n",
            "Name: Product, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJPUhu9ucDMC",
        "colab_type": "text"
      },
      "source": [
        "### Selects two types of products - credit reporting and mortgage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGAhdow-2oT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# credit reporting only\n",
        "credit_reporting = products_w_narrative[products_w_narrative['Product'] == \n",
        "                                        'Credit reporting, ' + \n",
        "                                        'credit repair services, or other personal consumer reports']\n",
        "# mortgage only\n",
        "mortgage = products_w_narrative[products_w_narrative['Product'] == 'Mortgage']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT9hYjQD2qvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "credit_narrative = credit_reporting['Consumer complaint narrative'].values\n",
        "positive_labels = pd.Series(np.ones(credit_narrative.shape[0]))\n",
        "positive_df = pd.DataFrame({'complaint': credit_narrative, 'label': \n",
        "                            positive_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev-bLnW02skW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mortgage_narrative = mortgage['Consumer complaint narrative'].values\n",
        "negative_labels = pd.Series(np.full(mortgage_narrative.shape[0], -1))\n",
        "negative_df = pd.DataFrame({'complaint': mortgage_narrative, 'label': \n",
        "                            negative_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2MfDm0XU8H5",
        "colab_type": "text"
      },
      "source": [
        "### Combine into one dataframe, create labels \n",
        "(1 for credit reporting, -1 for mortgage)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZZP4-on2ukd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b25e2d6-fcf3-4ebe-a44e-ca1e1cd963f2"
      },
      "source": [
        "complaints_df = pd.concat([positive_df, negative_df], ignore_index=True)\n",
        "complaints_df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(147508, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rX87qAw2wvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b1f31ff2-c112-4cf0-a868-39bff5341774"
      },
      "source": [
        "complaints_df['label'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1.0    94174\n",
              "-1.0    53334\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rJlMTGxVDPE",
        "colab_type": "text"
      },
      "source": [
        "### Split data into train, dev, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkY-5o7D2zFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, testval = train_test_split(complaints_df, test_size=0.2, random_state=123)\n",
        "dev, test = train_test_split(testval, test_size=0.5, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kv7_632VFL3",
        "colab_type": "text"
      },
      "source": [
        "## Create noisy labeling functions\n",
        "\n",
        "Our assumption is that we don't have the ground truth labels for our data, but instead have these noisy and possibly conflicting labels based on regular expressions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjA7CEoUci2C",
        "colab_type": "text"
      },
      "source": [
        "### Regular expressions that define words, phrases, actions for use in labeling functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i70mzuQ421Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AGENCY_NAMES = r'\\bexperian\\b|\\btransunion\\b|\\bequifax\\b|\\bfcra\\b'   \n",
        "DEBT_MENTIONS = r'\\bcollector\\b|\\bdebt\\b|\\bcreditor\\b'\n",
        "ADDRESS_MENTIONS = r'\\baddress\\b'\n",
        "DESCRIPTIONS = r'\\binaccura|\\bcompromise'\n",
        "IDENTITY = r'\\bidentity'\n",
        "CREDIT_REPORT_MENTIONS = r'\\bcredit (report|agency|reporting|bureau|agencies)'              \n",
        "MORTGAGE_MENTIONS = r'\\bloan\\b|\\bmortgage\\|\\bprepayment\\b|\\bprincipal\\b|\\binterest\\b|\\bescrow\\b'\n",
        "CHECKS = r'\\bcheck'\n",
        "TAXES = r'\\btax'\n",
        "LEASE = r'\\blease'\n",
        "HOUSE_MENTIONS = r'\\bhouse\\b|\\bhome\\bcondo\\b'\n",
        "MORTGAGE_HELP_ACTIONS = r'\\bmitigat|\\bmodifi\\brefinanc'\n",
        "MORTGAGE_COMPONENTS = r'\\bequity\\b|\\bdownpayment\\b|\\bshortage\\b'\n",
        "POSITIVE_ACTIONS = r'\\bremov|\\bdispute\\b' \n",
        "INQUIRY_ACTIONS  = r'\\binquir\\b|\\berror\\b'\n",
        "NEGATIVE_ACTIONS = r'\\bpredator|\\bapprove|\\bservic|\\bappraise|\\bforeclos'  \n",
        "                                                                      \n",
        "FRAUD = r'\\bfraudulent (account|charges)'                                               \n",
        "MONEYXFER = r'\\bmoney transfer'                                                         \n",
        "CREDIT_REPORTING = r'\\b(identity has been compromise(|d)|data breaches|inquiries to bus\\\n",
        "inesses|mistakes appear in my report|reporting incorrectly|dispute(|d)|(t|T)ransunion|derog\\\n",
        "atory|experian|identity theft)'                                                             \n",
        "CREDIT_REPAIR = r'\\b(credit repair|hard inquiry|inquiries to businesses|mistakes appear\\\n",
        " in my report|reporting incorrectly)'       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQzYfavwdWad",
        "colab_type": "text"
      },
      "source": [
        "### Labeling functions that help provide weak supervision\n",
        "\n",
        "In other words, instead of hand-labeling data to create a training set for our model, we write functions that look something like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0a_eu1223tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lf_agency_names(complaint):                                                                   \n",
        "    if re.search(AGENCY_NAMES, str(complaint), re.IGNORECASE):                            \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0            \n",
        "\n",
        "def lf_debt(complaint):                                                            \n",
        "    if re.search(DEBT_MENTIONS, str(complaint), re.IGNORECASE):                           \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0      \n",
        "\n",
        "def lf_address(complaint):                                                            \n",
        "    if re.search(ADDRESS_MENTIONS, str(complaint), re.IGNORECASE):\n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0     \n",
        "    \n",
        "def lf_credit_report(complaint):                                                           \n",
        "    if re.search(CREDIT_REPORT_MENTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0             \n",
        "    \n",
        "def lf_credit_actions(complaint):                                                           \n",
        "    if re.search(POSITIVE_ACTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return 1                                                                            \n",
        "    else:                                                                                   \n",
        "        return 0             \n",
        "    \n",
        "def lf_mortgage(complaint):                                                                 \n",
        "    if re.search(MORTGAGE_MENTIONS, str(complaint), re.IGNORECASE):                            \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0        \n",
        "    \n",
        "def lf_inquiry(complaint):                                                                 \n",
        "    if re.search(INQUIRY_ACTIONS, str(complaint), re.IGNORECASE):                            \n",
        "        return 1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0        \n",
        "    \n",
        "def lf_house_mentions(complaint):                                                         \n",
        "    if re.search(HOUSE_MENTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0          \n",
        "    \n",
        "def lf_mortgage_help(complaint):                                                         \n",
        "    if re.search(MORTGAGE_HELP_ACTIONS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0          \n",
        "    \n",
        "def lf_mortgage_components(complaint):                                                         \n",
        "    if re.search(MORTGAGE_COMPONENTS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0          \n",
        "    \n",
        "def lf_fraud(complaint):                                                                    \n",
        "    if (re.search(FRAUD, str(complaint), re.IGNORECASE)                                     \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                            \n",
        "    elif (re.search(FRAUD, str(complaint), re.IGNORECASE)                                   \n",
        "          and re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                         \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0     \n",
        "    \n",
        "def lf_reporting(complaint):                                                                \n",
        "    if (re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE)                          \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                            \n",
        "    elif (re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE)                        \n",
        "           and re.search(MONEYXFER, str(complaint), re.IGNORECASE)):                        \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0     \n",
        "\n",
        "def lf_repair(complaint):                                                                   \n",
        "    if (re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE)                             \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)                         \n",
        "        and not re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE)                  \n",
        "       ):                                                                                   \n",
        "        return 1                                                                            \n",
        "    elif ((re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE)                          \n",
        "           and re.search(MONEYXFER, str(complaint), re.IGNORECASE))                         \n",
        "          or                                                                                \n",
        "          (re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE)                          \n",
        "           and re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE))                  \n",
        "         ):                                                                                 \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0  \n",
        "\n",
        "def lf_credit_description(complaint):                                                                \n",
        "    if (re.search(DESCRIPTIONS, str(complaint), re.IGNORECASE)                          \n",
        "        and re.search(IDENTITY, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                                                                                             \n",
        "    else:                                                                                   \n",
        "        return 0           \n",
        "    \n",
        "def lf_description_not_mortgage(complaint):                                                                \n",
        "    if (re.search(DESCRIPTIONS, str(complaint), re.IGNORECASE)                          \n",
        "        and not re.search(MORTGAGE_MENTIONS, str(complaint), re.IGNORECASE)):                       \n",
        "        return 1                                                                                                                                             \n",
        "    else:                                                                                   \n",
        "        return 0           \n",
        "    \n",
        "def lf_tax(complaint):                                                         \n",
        "    if re.search(TAXES, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0    \n",
        "    \n",
        "def lf_check(complaint):                                                         \n",
        "    if re.search(CHECKS, str(complaint), re.IGNORECASE):                          \n",
        "        return -1                                                                           \n",
        "    else:                                                                                   \n",
        "        return 0    \n",
        "    \n",
        "def lf_lease(complaint):                                                         \n",
        "    if re.search(LEASE, str(complaint), re.IGNORECASE):                          \n",
        "        return 1                                                                          \n",
        "    else:                                                                                   \n",
        "        return 0    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_pBGXxdVTKV",
        "colab_type": "text"
      },
      "source": [
        "## Generate Snorkel objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1GW0OCXVUJi",
        "colab_type": "text"
      },
      "source": [
        "### Candidates and Contexts\n",
        "\n",
        "Candidate objects in Snorkel represent objects to be classified. In this case we are interested in classifying whether a complaint narrative is positive. A complaint narrative is positive when it is related to a credit complaint. \n",
        "\n",
        "All Candidate objects point to one or more Context objects representing the raw data that they are rooted in. In this case, our candidates will each point to a single Context object representing the raw text of the complaint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjVSxCjz26NK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3dd3cbcc-f26a-4d9e-fc72-c01a14a0ec57"
      },
      "source": [
        "session = SnorkelSession()\n",
        "\n",
        "values = list(complaints_df.label.unique())\n",
        "print(values)\n",
        "\n",
        "# snorkel candidate, value if none defaults to binary (true, false)\n",
        "Narrative = candidate_subclass('Narrative', ['narrative'], values=values)\n",
        "\n",
        "# Make sure DB is cleared\n",
        "session.query(Context).delete()\n",
        "session.query(Candidate).delete()\n",
        "session.query(StableLabel).delete()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, -1.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcRDtTkoViEb",
        "colab_type": "text"
      },
      "source": [
        "Once we have defined the context for each candidate, we split it into three sets :\n",
        "\n",
        "- Training set (split=0): This is the set of narratives that we will examine in order to write labeling functions for. The labeling functions that we write will be noisy and conflicting. We will resolve these conflicts using the generative model. The generative model outputs a set of probabilistic labels which we use to train the discriminative model. The discriminative model is the standard goal in machine learning that learns to generalize beyond the training set.\n",
        "\n",
        "- Development/ validation set (split=1): We will pretend that we do not have any noisy, conflicting labels for this split of the data, and it is used to help iterate the generative model training process. In later steps we also use it to test the discriminative model's (RNN in this case) performance on unseen data. \n",
        "\n",
        "- Test set (split=2): We will pretend that we do not have any noisy, conflicting labels for this split of the data, and use it to test the discriminative model's (RNN in this case) performance on unseen data   \n",
        "\n",
        "We then commit it to the database."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jypxk-b_3BAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e93863e7-3b9b-4dc8-b8bb-030a91b8ec18"
      },
      "source": [
        "train_index = train.index\n",
        "train.index.str = np.asarray(str(x) for x in train.index)\n",
        "train_complaints = train.values[:, 0]\n",
        "train_labels = train.values[:, 1]\n",
        "\n",
        "for element in zip(train_index, train_complaints, train_labels):\n",
        "    split = 0\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], \n",
        "                       text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "\n",
        "dev_index = dev.index\n",
        "dev.index.str = np.asarray(str(x) for x in dev.index)\n",
        "dev_complaints = dev.values[:, 0]\n",
        "dev_labels = dev.values[:, 1]\n",
        "\n",
        "for element in zip(dev_index, dev_complaints, dev_labels):\n",
        "    split = 1\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], \n",
        "                       text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "\n",
        "test_index = test.index\n",
        "test.index.str = np.asarray(str(x) for x in test.index)\n",
        "test_complaints = test.values[:, 0]\n",
        "test_labels = test.values[:, 1]\n",
        "\n",
        "for element in zip(test_index, test_complaints, test_labels):\n",
        "    split = 2\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], \n",
        "                       text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "\n",
        "session.commit()\n",
        "\n",
        "# number of datapoints\n",
        "print(\"number of datapoints in candidate: \", session.query(Narrative).count())\n",
        "\n",
        "# load ground truth labels\n",
        "train_cand_labels = train_labels\n",
        "dev_cand_labels = dev_labels\n",
        "test_cand_labels = test_labels"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of datapoints in candidate:  147508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8--icqpq3JuM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8df63ec6-077b-49f1-d113-036d5292b753"
      },
      "source": [
        "# test one labeling function\n",
        "labeled = []\n",
        "for c in session.query(Narrative).filter(Narrative.split == 1).all():\n",
        "    if lf_tax(c) != 0:\n",
        "        labeled.append(c)\n",
        "print(\"Number labeled:\", len(labeled))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number labeled: 954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpOVOJiKVoSn",
        "colab_type": "text"
      },
      "source": [
        "### Labels\n",
        "\n",
        "Next, we assign labeling functions for each of the training candidates in a sparse matrix (which will also automatically be saved to the Snorkel database), with one row for each candidate and one column for each label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQnhzeaf3nrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "473c413b-26e8-417b-80c8-8bf70d105720"
      },
      "source": [
        "LFs = [lf_agency_names, lf_debt, lf_address, lf_credit_report, lf_credit_actions, \n",
        "       lf_inquiry, lf_mortgage, lf_house_mentions, lf_mortgage_components,\n",
        "       lf_mortgage_help, lf_fraud, lf_reporting, lf_repair,\n",
        "       lf_credit_description, lf_description_not_mortgage,\n",
        "       lf_tax, lf_check, lf_lease]\n",
        "# apply labeling functions\n",
        "labeler = LabelAnnotator(lfs = LFs)\n",
        "L_train = labeler.apply(split=0)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 24/118006 [00:00<08:24, 233.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n",
            "Running UDF...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 118006/118006 [07:55<00:00, 248.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCtH_AV-3scM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "f87c1201-7d3e-4c2d-ebea-92ea11f02b5e"
      },
      "source": [
        "# see what's going on\n",
        "print(L_train.get_candidate(session, 0))\n",
        "print(L_train.get_key(session, 0))\n",
        "print(L_train.lf_stats(session))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Narrative(Raw Text XXXX XXXX XXXX- XX-XX-2016 Experian XXXX XXXX XXXX -XX/XX/2016 XXXX XXXX XXXX-XX/XX/2016 XXXX XXXX XXXX-XX/XX/2016 The inquiries that I have written above are unauthorized. I did not allow anyone to use my personal information to obtain goods. Experian and XXXX have not removed the fraud inquiries from my credit report even though i have disputed them multiple times.)\n",
            "LabelKey (lf_agency_names)\n",
            "                              j  Coverage  Overlaps  Conflicts\n",
            "lf_agency_names               0  0.279071  0.260402   0.060726\n",
            "lf_debt                       1  0.145620  0.138315   0.058039\n",
            "lf_address                    2  0.099410  0.094216   0.047345\n",
            "lf_credit_report              3  0.437503  0.394946   0.141162\n",
            "lf_credit_actions             4  0.328822  0.313332   0.110020\n",
            "lf_inquiry                    5  0.061200  0.058395   0.035981\n",
            "lf_mortgage                   6  0.355897  0.262554   0.180593\n",
            "lf_house_mentions             7  0.081970  0.073657   0.037490\n",
            "lf_mortgage_components        8  0.032303  0.031092   0.015508\n",
            "lf_mortgage_help              9  0.013660  0.012016   0.005974\n",
            "lf_fraud                     10  0.020448  0.019702   0.003932\n",
            "lf_reporting                 11  0.322128  0.315374   0.099317\n",
            "lf_repair                    12  0.027456  0.025677   0.019202\n",
            "lf_credit_description        13  0.012694  0.012694   0.002796\n",
            "lf_description_not_mortgage  14  0.077157  0.073318   0.009279\n",
            "lf_tax                       15  0.066124  0.063090   0.033710\n",
            "lf_check                     16  0.123384  0.111901   0.079784\n",
            "lf_lease                     17  0.010389  0.009661   0.005762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6CcudVdVvxk",
        "colab_type": "text"
      },
      "source": [
        "## Training generative model\n",
        "\n",
        "\n",
        "The problem with the above labeling functions is that they're noisy, conflicting and may even overlap on certain examples. The key technical idea of Snorkel's generative modeling approach is that we can automatically model and denoise them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbo3wzLj5ukd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "146cae96-582a-45ce-8b4a-87a4478bc11e"
      },
      "source": [
        "# Initialize Snorkel's generative model for\n",
        "# learning the different worker accuracies.\n",
        "gen_model = GenerativeModel(lf_propensity=True)\n",
        "gen_model.train(L_train, epochs=20, decay=0.95, step_size=0.1/L_train.shape[0], \n",
        "                reg_param=1e-6)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inferred cardinality: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XgNEwhsV31e",
        "colab_type": "text"
      },
      "source": [
        "## Applying the generative model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiKU0A_2gjZU",
        "colab_type": "text"
      },
      "source": [
        "### Probabilistic Label Statistics\n",
        "\n",
        "We view the distribution of weak labels produced by our generative model. Note that the samples in the 0.5 bucket indicate the ones that have no LF coverage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-pU4eS5_Na",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "44fec1dd-04e1-46a2-b7e2-75e54a486b3b"
      },
      "source": [
        "train_marginals = gen_model.marginals(L_train)\n",
        "plt.hist(train_marginals, bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAFOhJREFUeJzt3X+MXeV95/H3J+ZH2E1SmzBFyHbW\nbOOq67CqQ2bBVVe7adgYQ6SYqtkIpBYXobjbwKrdjaqQ7h+kECTQKkGLROg6ixdTtTEs/YHVmvVa\nhBXKag0MhQCGZpkCKfY62MX8aIRKFvLdP+7j9sZnxnM9M54743m/pKM593uec+7z2KP5zDnnuWdS\nVUiS1O89w+6AJGn+MRwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jhl2B2YrrPO\nOqtWrVo17G5I0oLy+OOP/3VVjUzVbsGGw6pVqxgbGxt2NyRpQUnyvUHaTXlZKcl7kzya5DtJ9ib5\nnVa/K8mLSZ5sy9pWT5LbkowneSrJ+X3H2pTk+bZs6qt/LMnTbZ/bkuT4hyxJmi2DnDm8DXyiqn6Q\n5FTg20keaNt+q6ruO6r9JcDqtlwI3AFcmORM4HpgFCjg8SQ7quq11uZzwCPATmAD8ACSpKGY8syh\nen7QXp7almM9ynUjcHfbbw+wNMk5wMXA7qo63AJhN7ChbftAVe2p3iNi7wYum8GYJEkzNNBspSRL\nkjwJHKT3A/6Rtummduno1iSnt9py4OW+3fe12rHq+yaoS5KGZKBwqKp3q2otsAK4IMl5wJeAnwH+\nGXAm8MUT1ssmyeYkY0nGDh06dKLfTpIWreP6nENVvQ48BGyoqgPt0tHbwH8FLmjN9gMr+3Zb0WrH\nqq+YoD7R+2+pqtGqGh0ZmXImliRpmgaZrTSSZGlbPwP4JPAX7V4BbWbRZcAzbZcdwJVt1tI64I2q\nOgDsAtYnWZZkGbAe2NW2vZlkXTvWlcD9sztMSdLxGGS20jnAtiRL6IXJvVX1p0m+lWQECPAk8G9a\n+53ApcA48BZwFUBVHU5yI/BYa3dDVR1u658H7gLOoDdLyZlKkjREWah/Q3p0dLT8EJwkHZ8kj1fV\n6FTtFuwnpCVpoVp13Z9Ne9+Xbv7ULPZkcj54T5LUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAk\ndRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH\n4SBJ6jAcJEkdU4ZDkvcmeTTJd5LsTfI7rX5ukkeSjCe5J8lprX56ez3etq/qO9aXWv27SS7uq29o\ntfEk183+MCVJx2OQM4e3gU9U1c8Ca4ENSdYBtwC3VtWHgdeAq1v7q4HXWv3W1o4ka4DLgY8AG4Cv\nJ1mSZAlwO3AJsAa4orWVJA3JlOFQPT9oL09tSwGfAO5r9W3AZW19Y3tN235RkrT69qp6u6peBMaB\nC9oyXlUvVNUPge2trSRpSAa659B+w38SOAjsBv4SeL2q3mlN9gHL2/py4GWAtv0N4IP99aP2maw+\nUT82JxlLMnbo0KFBui5JmoaBwqGq3q2qtcAKer/p/8wJ7dXk/dhSVaNVNToyMjKMLkjSonBcs5Wq\n6nXgIeDngKVJTmmbVgD72/p+YCVA2/4TwKv99aP2mawuSRqSQWYrjSRZ2tbPAD4JPEcvJD7Tmm0C\n7m/rO9pr2vZvVVW1+uVtNtO5wGrgUeAxYHWb/XQavZvWO2ZjcJKk6Tll6iacA2xrs4reA9xbVX+a\n5Flge5KvAE8Ad7b2dwK/l2QcOEzvhz1VtTfJvcCzwDvANVX1LkCSa4FdwBJga1XtnbURSpKO25Th\nUFVPAR+doP4CvfsPR9f/FvjXkxzrJuCmCeo7gZ0D9FeSNAf8hLQkqcNwkCR1GA6SpA7DQZLUYThI\nkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySp\nw3CQJHUYDpKkDsNBktRhOEiSOqYMhyQrkzyU5Nkke5P8Rqt/Ocn+JE+25dK+fb6UZDzJd5Nc3Fff\n0GrjSa7rq5+b5JFWvyfJabM9UEnS4AY5c3gH+EJVrQHWAdckWdO23VpVa9uyE6Btuxz4CLAB+HqS\nJUmWALcDlwBrgCv6jnNLO9aHgdeAq2dpfJKkaZgyHKrqQFX9eVv/G+A5YPkxdtkIbK+qt6vqRWAc\nuKAt41X1QlX9ENgObEwS4BPAfW3/bcBl0x2QJGnmjuueQ5JVwEeBR1rp2iRPJdmaZFmrLQde7ttt\nX6tNVv8g8HpVvXNUXZI0JAOHQ5L3AX8I/GZVvQncAfwUsBY4AHz1hPTwx/uwOclYkrFDhw6d6LeT\npEVroHBIciq9YPj9qvojgKp6pareraofAd+gd9kIYD+wsm/3Fa02Wf1VYGmSU46qd1TVlqoararR\nkZGRQbouSZqGQWYrBbgTeK6qvtZXP6ev2S8Cz7T1HcDlSU5Pci6wGngUeAxY3WYmnUbvpvWOqirg\nIeAzbf9NwP0zG5YkaSZOmboJPw/8CvB0kidb7bfpzTZaCxTwEvBrAFW1N8m9wLP0ZjpdU1XvAiS5\nFtgFLAG2VtXedrwvAtuTfAV4gl4YSZKGZMpwqKpvA5lg085j7HMTcNME9Z0T7VdVL/D3l6UkSUPm\nJ6QlSR2GgySpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7D\nQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1DFlOCRZmeShJM8m2ZvkN1r9\nzCS7kzzfvi5r9SS5Lcl4kqeSnN93rE2t/fNJNvXVP5bk6bbPbUlyIgYrSRrMIGcO7wBfqKo1wDrg\nmiRrgOuAB6tqNfBgew1wCbC6LZuBO6AXJsD1wIXABcD1RwKltflc334bZj40SdJ0TRkOVXWgqv68\nrf8N8BywHNgIbGvNtgGXtfWNwN3VswdYmuQc4GJgd1UdrqrXgN3AhrbtA1W1p6oKuLvvWJKkITiu\new5JVgEfBR4Bzq6qA23T94Gz2/py4OW+3fa12rHq+yaoS5KGZOBwSPI+4A+B36yqN/u3td/4a5b7\nNlEfNicZSzJ26NChE/12krRoDRQOSU6lFwy/X1V/1MqvtEtCtK8HW30/sLJv9xWtdqz6ignqHVW1\npapGq2p0ZGRkkK5LkqZhkNlKAe4Enquqr/Vt2gEcmXG0Cbi/r35lm7W0DnijXX7aBaxPsqzdiF4P\n7Grb3kyyrr3XlX3HkiQNwSkDtPl54FeAp5M82Wq/DdwM3JvkauB7wGfbtp3ApcA48BZwFUBVHU5y\nI/BYa3dDVR1u658H7gLOAB5oiyRpSKYMh6r6NjDZ5w4umqB9AddMcqytwNYJ6mPAeVP1RZI0N/yE\ntCSpw3CQJHUYDpKkDsNBktRhOEiSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLUYThI\nkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgOkqQOw0GS1GE4SJI6pgyHJFuTHEzyTF/ty0n2J3my\nLZf2bftSkvEk301ycV99Q6uNJ7mur35ukkda/Z4kp83mACVJx2+QM4e7gA0T1G+tqrVt2QmQZA1w\nOfCRts/XkyxJsgS4HbgEWANc0doC3NKO9WHgNeDqmQxIkjRzU4ZDVT0MHB7weBuB7VX1dlW9CIwD\nF7RlvKpeqKofAtuBjUkCfAK4r+2/DbjsOMcgSZplM7nncG2Sp9plp2Wtthx4ua/NvlabrP5B4PWq\neueouiRpiKYbDncAPwWsBQ4AX521Hh1Dks1JxpKMHTp0aC7eUpIWpWmFQ1W9UlXvVtWPgG/Qu2wE\nsB9Y2dd0RatNVn8VWJrklKPqk73vlqoararRkZGR6XRdkjSAaYVDknP6Xv4icGQm0w7g8iSnJzkX\nWA08CjwGrG4zk06jd9N6R1UV8BDwmbb/JuD+6fRJkjR7TpmqQZJvAh8HzkqyD7ge+HiStUABLwG/\nBlBVe5PcCzwLvANcU1XvtuNcC+wClgBbq2pve4svAtuTfAV4Arhz1kYnSZqWKcOhqq6YoDzpD/Cq\nugm4aYL6TmDnBPUX+PvLUpKkecBPSEuSOgwHSVKH4SBJ6jAcJEkdhoMkqcNwkCR1GA6SpA7DQZLU\nMeWH4KSZWHXdn01735du/tQs9kTS8fDMQZLUYThIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdRgO\nkqQOPwQnTcAP72mxMxwkaRpm8gvEQuBlJUlSh+EgSeowHCRJHVOGQ5KtSQ4meaavdmaS3Umeb1+X\ntXqS3JZkPMlTSc7v22dTa/98kk199Y8lebrtc1uSzPYgJUnHZ5Azh7uADUfVrgMerKrVwIPtNcAl\nwOq2bAbugF6YANcDFwIXANcfCZTW5nN9+x39XpKkOTZlOFTVw8Dho8obgW1tfRtwWV/97urZAyxN\ncg5wMbC7qg5X1WvAbmBD2/aBqtpTVQXc3XcsSdKQTPeew9lVdaCtfx84u60vB17ua7ev1Y5V3zdB\nfUJJNicZSzJ26NChaXZdkjSVGd+Qbr/x1yz0ZZD32lJVo1U1OjIyMhdvKUmL0nTD4ZV2SYj29WCr\n7wdW9rVb0WrHqq+YoC5JGqLphsMO4MiMo03A/X31K9uspXXAG+3y0y5gfZJl7Ub0emBX2/ZmknVt\nltKVfceSJA3JlI/PSPJN4OPAWUn20Zt1dDNwb5Krge8Bn23NdwKXAuPAW8BVAFV1OMmNwGOt3Q1V\ndeQm9+fpzYg6A3igLZKkIZoyHKrqikk2XTRB2wKumeQ4W4GtE9THgPOm6ockae74CWlJUofhIEnq\nMBwkSR2GgySpw3CQJHUYDpKkDsNBktTh35BeJGby925fuvlTs9gTSQuBZw6SpA7DQZLUYThIkjq8\n5yBpwZrJvTTwftqxGA6SFq2ZhsvJzMtKkqQOw0GS1GE4SJI6DAdJUofhIEnqMBwkSR2GgySpw885\nSBoqP2swP83ozCHJS0meTvJkkrFWOzPJ7iTPt6/LWj1JbksynuSpJOf3HWdTa/98kk0zG5IkaaZm\n47LSL1TV2qoaba+vAx6sqtXAg+01wCXA6rZsBu6AXpgA1wMXAhcA1x8JFEnScJyIew4bgW1tfRtw\nWV/97urZAyxNcg5wMbC7qg5X1WvAbmDDCeiXJGlAMw2HAv5HkseTbG61s6vqQFv/PnB2W18OvNy3\n775Wm6wuSRqSmd6Q/udVtT/JTwK7k/xF/8aqqiQ1w/f4Oy2ANgN86EMfmq3DSsK/FqgfN6Mzh6ra\n374eBP6Y3j2DV9rlItrXg635fmBl3+4rWm2y+kTvt6WqRqtqdGRkZCZdlyQdw7TDIck/TPL+I+vA\neuAZYAdwZMbRJuD+tr4DuLLNWloHvNEuP+0C1idZ1m5Er281SdKQzOSy0tnAHyc5cpw/qKr/nuQx\n4N4kVwPfAz7b2u8ELgXGgbeAqwCq6nCSG4HHWrsbqurwDPolSZqhaYdDVb0A/OwE9VeBiyaoF3DN\nJMfaCmydbl8kSbPLx2dIkjoMB0lSh+EgSeowHCRJHYaDJKnDcJAkdfj3HDRvzfQ5/z7SQZo+w0Ga\nZcN8RpF/OEezxctKkqQOw0GS1GE4SJI6vOcwh7zBKmmh8MxBktRhOEiSOgwHSVKH4SBJ6jAcJEkd\nzlaS5hE/4az5wnCQNGOG2snHy0qSpA7DQZLUMW8uKyXZAPwnYAnwX6rq5iF3SY2XDKTFZ16EQ5Il\nwO3AJ4F9wGNJdlTVs8PtWZc/KBcO/6+k6Zsvl5UuAMar6oWq+iGwHdg45D5J0qI1L84cgOXAy32v\n9wEXDqkv85a/CUuaK/MlHAaSZDOwub38QZJXgb8eYpeG7SwW7/gX89jB8S/a8eeWGY/9Hw3SaL6E\nw35gZd/rFa32Y6pqC7DlyOskY1U1euK7Nz8t5vEv5rGD41/M45+rsc+Xew6PAauTnJvkNOByYMeQ\n+yRJi9a8OHOoqneSXAvsojeVdWtV7R1ytyRp0ZoX4QBQVTuBnce525apm5zUFvP4F/PYwfEv5vHP\nydhTVXPxPpKkBWS+3HOQJM0jCyIckmxI8t0k40mum2D76UnuadsfSbJq7nt5Ygww9n+f5NkkTyV5\nMMlA09QWiqnG39ful5JUkpNqBssg40/y2fY9sDfJH8x1H0+UAb73P5TkoSRPtO//S4fRzxMlydYk\nB5M8M8n2JLmt/fs8leT8We1AVc3rhd4N6r8E/jFwGvAdYM1RbT4P/G5bvxy4Z9j9nsOx/wLwD9r6\nr58sYx90/K3d+4GHgT3A6LD7Pcf//6uBJ4Bl7fVPDrvfczj2LcCvt/U1wEvD7vcs/xv8C+B84JlJ\ntl8KPAAEWAc8MpvvvxDOHAZ5tMZGYFtbvw+4KEnmsI8nypRjr6qHquqt9nIPvc+InCwGfazKjcAt\nwN/OZefmwCDj/xxwe1W9BlBVB+e4jyfKIGMv4ANt/SeA/zuH/Tvhquph4PAxmmwE7q6ePcDSJOfM\n1vsvhHCY6NEayydrU1XvAG8AH5yT3p1Yg4y939X0fpM4WUw5/nYqvbKqTsZniwzy///TwE8n+V9J\n9rSnG58MBhn7l4FfTrKP3kzHfzs3XZs3jvfnw3GZN1NZNTNJfhkYBf7lsPsyV5K8B/ga8KtD7sow\nnULv0tLH6Z01Ppzkn1bV60Pt1dy4Arirqr6a5OeA30tyXlX9aNgdOxkshDOHQR6t8XdtkpxC7xTz\n1Tnp3Yk10GNFkvwr4D8An66qt+eob3NhqvG/HzgP+J9JXqJ33XXHSXRTepD//33Ajqr6f1X1IvB/\n6IXFQjfI2K8G7gWoqv8NvJfeM5cWi4F+PkzXQgiHQR6tsQPY1NY/A3yr2h2bBW7KsSf5KPCf6QXD\nyXK9+Yhjjr+q3qiqs6pqVVWtonfP5dNVNTac7s66Qb73/4TeWQNJzqJ3memFuezkCTLI2P8KuAgg\nyT+hFw6H5rSXw7UDuLLNWloHvFFVB2br4PP+slJN8miNJDcAY1W1A7iT3inlOL0bOJcPr8ezZ8Cx\n/0fgfcB/a/fg/6qqPj20Ts+iAcd/0hpw/LuA9UmeBd4FfquqFvxZ84Bj/wLwjST/jt7N6V89SX4p\nBCDJN+kF/1ntvsr1wKkAVfW79O6zXAqMA28BV83q+59E/5aSpFmyEC4rSZLmmOEgSeowHCRJHYaD\nJKnDcJAkdRgOkqQOw0GS1GE4SJI6/j/2UZdNFDHvOQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tteWMMziXPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2419915f-2278-4872-8111-86d50d40a8e1"
      },
      "source": [
        "print(\"So we have \", (train_marginals == 0.5).sum(), \n",
        "      \" samples where the LFs do not provide any coverage!\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "So we have  10410  samples where the LFs do not provide any coverage!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdSWOLOHV8xM",
        "colab_type": "text"
      },
      "source": [
        "### Compare learned accuracies vs empirical accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BJFOfWVjNjf",
        "colab_type": "text"
      },
      "source": [
        "#### Learned accuracies from our generative model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu6pQmGf8a60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a27b07f-fdf2-4188-82dd-197b3d97bb30"
      },
      "source": [
        "accuracy = gen_model.score(L_train, train_cand_labels)\n",
        "print(\"precision: {:.5f}\".format(accuracy[0]), \n",
        "      \"recall: {:.5f}\".format(accuracy[1]), \n",
        "      \"F1: {:.5f}\".format(accuracy[2]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.85558 recall: 0.90212 F1: 0.87823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbPGL0eikcX1",
        "colab_type": "text"
      },
      "source": [
        "#### Empirical accuracies of our labeling functions - majority vote\n",
        "\n",
        "We observe that the majority vote approach does almost as well as the generative model for our use case! The labeling functions that we have defined are pretty simple but quite effective, they essentially look at certain keywords. In a realistic scenario, a labeling function that looks at the presence of certain keywords may not be as effective.  One may also derive labeling functions based on knowledge bases, distant supervision, or even crowd-source them causing it to be more noisy and imprecise in which case the generative model will more likely outperform the majority vote."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAHOrwAi8wia",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "30fecc4b-553e-4135-9bc3-d6190374e841"
      },
      "source": [
        "# Collect the majority vote answer for each complaint\n",
        "mv = []\n",
        "for i in range(L_train.shape[0]):\n",
        "    #indicates that there is no coverage for a particular datapoint\n",
        "    if np.diff(L_train[i].indptr) != 0:   \n",
        "        c = Counter([L_train[i,j] for j in L_train[i].nonzero()[1]])\n",
        "        mv.append(c.most_common(1)[0][0])\n",
        "    else:\n",
        "        # assume that no label is equivalent to abstaining\n",
        "        mv.append(0) \n",
        "mv = np.array(mv)\n",
        "\n",
        "# Count the number correct by majority vote\n",
        "n_correct = np.sum([1 for i in range(L_train.shape[0]) if mv[i] == \n",
        "                    train_cand_labels[i]])\n",
        "print (\"Accuracy:{}\".format(n_correct / float(L_train.shape[0])))\n",
        "print (\"Number incorrect:{}\".format(L_train.shape[0] - n_correct))\n",
        "\n",
        "# Compute and return precision, recall\n",
        "tp = (0.5 * (mv * train_cand_labels + 1))[mv == 1].sum()\n",
        "pred_pos = mv[mv == 1].sum()\n",
        "p = tp / float(pred_pos) if pred_pos > 0 else 0.0\n",
        "pos = train_cand_labels[train_cand_labels == 1].sum()\n",
        "r = tp / float(pos) if pos > 0 else 0.0\n",
        "\n",
        "# Compute general F-beta score\n",
        "beta=1\n",
        "if p + r > 0:\n",
        "    f_beta = (1 + beta**2) * ((p * r) / (((beta**2) * p) + r))\n",
        "else:\n",
        "    f_beta = 0.0\n",
        "\n",
        "print(\"precision: {:.5f}\".format(p), \n",
        "      \"recall: {:.5f}\".format(r), \n",
        "      \"F1: {:.5f}\".format(f_beta))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.8069589681880582\n",
            "Number incorrect:22780\n",
            "precision: 0.87312 recall: 0.89479 F1: 0.88382\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot9U8G1jWEjO",
        "colab_type": "text"
      },
      "source": [
        "#### Performance on dev set\n",
        "\n",
        "We can also get a more detailed score (true positives, false positives, true negatives, false negatives) on the dev set and iterate on the generative training process if we need to"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFUbHlys9M4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "25300a03-50ff-44de-9c7a-ff66b830227c"
      },
      "source": [
        "L_dev = labeler.apply(split=1)\n",
        "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, dev_cand_labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 25/14751 [00:00<01:00, 243.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running UDF...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14751/14751 [00:58<00:00, 251.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Scores (Un-adjusted)\n",
            "========================================\n",
            "Pos. class accuracy: 0.901\n",
            "Neg. class accuracy: 0.74\n",
            "Precision            0.859\n",
            "Recall               0.901\n",
            "F1                   0.88\n",
            "----------------------------------------\n",
            "TP: 8484 | FP: 1390 | TN: 3948 | FN: 929\n",
            "========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1w-dKHZ8TMF",
        "colab_type": "text"
      },
      "source": [
        "Saving the predictions of the generative model on the train set back to the database for future use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yNNLBQ89vVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c02ffae-e79d-49e6-bccd-2abeb565a873"
      },
      "source": [
        "save_marginals(session, L_train, train_marginals)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved 118006 marginals\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEUbvftvWOII",
        "colab_type": "text"
      },
      "source": [
        "## Training a *noise-aware* discriminative model\n",
        "\n",
        "In this step we set up a noise-aware discriminative model in TensorFlow and see how close we come to the fully supervised version!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKSfYJpknSCL",
        "colab_type": "text"
      },
      "source": [
        "### First, load the candidates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO3eCdQp924i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cands = session.query(Narrative).filter(Narrative.split == 0).order_by(Narrative.id).all()\n",
        "dev_cands   = session.query(Narrative).filter(Narrative.split == 1).order_by(Narrative.id).all()\n",
        "test_cands  = session.query(Narrative).filter(Narrative.split == 2).order_by(Narrative.id).all()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msbrZQc_noPo",
        "colab_type": "text"
      },
      "source": [
        "### Train model using RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSAjjnerWX6U",
        "colab_type": "text"
      },
      "source": [
        "We decided to leverage Snorkel's built-in discriminative classifier and made some custom changes to work with our example. \n",
        "\n",
        "Note, how the number of training samples below are lower than what's present in the training set, it excludes samples where there was no LF coverage, that is it trains on train_marginals.shape[0] - (train_marginals == 0.5).sum() samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvoqgKfq932D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "42e0fbf0-e749-4bd5-d2ce-be429a34a6cc"
      },
      "source": [
        "train_kwargs = {\n",
        "    'lr':         0.01,\n",
        "    'dim':        100,\n",
        "    'n_epochs':   10,\n",
        "    'dropout':    0.2,\n",
        "    'print_freq': 1,\n",
        "    'seed': 123,\n",
        "    'batch_size': 200,\n",
        "    'max_sentence_length': 512,\n",
        "    'vocab_size': 5000\n",
        "}\n",
        "\n",
        "lstm = TextRNN(seed=123, cardinality=Narrative.cardinality)\n",
        "# Note: Y_train are the marginals but Y_dev are the gold/ ground truth labels\n",
        "lstm.train(X_train=train_cands, Y_train=train_marginals, X_dev=dev_cands, \n",
        "           Y_dev=dev_cand_labels, **train_kwargs)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max sentence len in training data:  5729\n",
            "but capped to:  512\n",
            "And also curtailing warning(s) related to checking individual max sentence lengths in each narrative\n",
            "currrent vocab size is:  169085\n",
            "but capped to:  5000\n",
            "[TextRNN] Training model\n",
            "[TextRNN] n_train=107596  #epochs=10  batch size=200\n",
            "[TextRNN] Epoch 0 (475.78s)\tAverage loss=0.456591\tDev F1=91.58\n",
            "[TextRNN] Epoch 1 (975.30s)\tAverage loss=0.405692\tDev F1=90.73\n",
            "[TextRNN] Epoch 2 (1477.42s)\tAverage loss=0.407588\tDev F1=90.67\n",
            "[TextRNN] Epoch 3 (1978.29s)\tAverage loss=0.405001\tDev F1=90.93\n",
            "[TextRNN] Epoch 4 (2479.33s)\tAverage loss=0.401411\tDev F1=90.68\n",
            "[TextRNN] Epoch 5 (2977.22s)\tAverage loss=0.398706\tDev F1=90.36\n",
            "[TextRNN] Epoch 6 (3475.51s)\tAverage loss=0.397765\tDev F1=90.11\n",
            "[TextRNN] Epoch 7 (3977.36s)\tAverage loss=0.397443\tDev F1=89.39\n",
            "[TextRNN] Epoch 8 (4478.05s)\tAverage loss=0.398661\tDev F1=89.85\n",
            "[TextRNN] Model saved as <TextRNN>\n",
            "[TextRNN] Epoch 9 (4977.81s)\tAverage loss=0.397797\tDev F1=89.77\n",
            "[TextRNN] Training done (5004.14s)\n",
            "currrent vocab size is:  169085\n",
            "but capped to:  5000\n",
            "[TextRNN] Loaded model <TextRNN>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-wA6gEfWhl1",
        "colab_type": "text"
      },
      "source": [
        "### Accuracies on dev and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZBYLyyW-LdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c22ec3d-d6e9-49d3-e2ec-46ee17c6cb84"
      },
      "source": [
        "accuracy_dev = lstm.score(dev_cands, dev_cand_labels, batch_size=200)\n",
        "print(\"precision: {:.5f}\".format(accuracy_dev[0]), \n",
        "      \"recall: {:.5f}\".format(accuracy_dev[1]), \n",
        "      \"F1: {:.5f}\".format(accuracy_dev[2]))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.83499 recall: 0.97248 F1: 0.89851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlC3vfgA-Nse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0afe2cee-301f-4923-a13a-e104e7dcf5a7"
      },
      "source": [
        "accuracy_test = lstm.score(test_cands, test_cand_labels, batch_size=200)\n",
        "print(\"precision: {:.5f}\".format(accuracy_test[0]), \n",
        "      \"recall: {:.5f}\".format(accuracy_test[1]), \n",
        "      \"F1: {:.5f}\".format(accuracy_test[2]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.83533 recall: 0.97251 F1: 0.89872\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}