{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snorkel-demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fastforwardlabs/snorkel-demo-colab/blob/master/snorkel_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2hgkWoEUODX",
        "colab_type": "text"
      },
      "source": [
        "## Training a text classification model using noisy regular expressions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q40cmhf21u79",
        "colab_type": "code",
        "outputId": "777ef24c-d57d-4b82-9941-638cb0c85e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install -r requirements.txt\n",
        "#!pip3 install git+https://github.com/HazyResearch/snorkel\n",
        "!pip3 install git+https://github.com/nishamuktewar/snorkel\n",
        "!pip3 install treedlib\n",
        "!pip3 install numbskull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting beautifulsoup4==4.7.1 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/5d/3260694a59df0ec52f8b4883f5d23b130bc237602a1411fa670eae12351e/beautifulsoup4-4.7.1-py3-none-any.whl (94kB)\n",
            "\r\u001b[K     |███▌                            | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 20kB 25.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 30kB 30.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 40kB 34.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 51kB 38.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 61kB 41.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 71kB 43.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 81kB 44.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 92kB 46.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 32.3MB/s \n",
            "\u001b[?25hCollecting future==0.17.1 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/52/e20466b85000a181e1e144fd8305caf2cf475e2f9674e797b222f8105f5f/future-0.17.1.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 50.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets==7.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (7.4.2)\n",
            "Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.0.0)\n",
            "Collecting lxml==4.3.3 (from -r requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/8a/5e066949f2b40caac32c7b2a77da63ad304b5fbe869036cc3fe4a198f724/lxml-4.3.3-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 46.9MB/s \n",
            "\u001b[?25hCollecting matplotlib==3.0.1 (from -r requirements.txt (line 6))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/f8/4aba1144dad8c67db060049d1a8bc740ad9fa35288d21b82bb85de69ff15/matplotlib-3.0.1-cp36-cp36m-manylinux1_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (3.2.5)\n",
            "Collecting numba==0.43.1 (from -r requirements.txt (line 8))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/c6/b28f5cada2aca31018a8bb210065f9b6a3174d25a80a9961c7bd3e831c3e/numba-0.43.1-cp36-cp36m-manylinux1_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 47.8MB/s \n",
            "\u001b[?25hCollecting numpy==1.16.1 (from -r requirements.txt (line 9))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 43.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.24.2)\n",
            "Collecting py4j==0.10.8.1 (from -r requirements.txt (line 11))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/de/2d314a921ef4c20b283e1de94e0780273678caac901564df06b948e4ba9b/py4j-0.10.8.1-py2.py3-none-any.whl (196kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.7MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0 (from -r requirements.txt (line 12))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 24.3MB/s \n",
            "\u001b[?25hCollecting runipy==0.1.5 (from -r requirements.txt (line 13))\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/b7/628258778b5b6da373dda3053241bf5f7d80ee65941ad3ad219fb3e9356f/runipy-0.1.5.tar.gz\n",
            "Collecting scipy==1.2.1 (from -r requirements.txt (line 14))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six==1.12.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (1.12.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 16)) (2.1.4)\n",
            "Collecting sqlalchemy==1.3.3 (from -r requirements.txt (line 17))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/b2/e6f5c5efc68942edefaa924e8fbea0b32375baa434a511cbf6bb17769cf6/SQLAlchemy-1.3.3.tar.gz (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 46.4MB/s \n",
            "\u001b[?25hCollecting tika==1.19 (from -r requirements.txt (line 18))\n",
            "  Downloading https://files.pythonhosted.org/packages/10/75/b566e446ffcf292f10c8d84c15a3d91615fe3d7ca8072a17c949d4e84b66/tika-1.19.tar.gz\n",
            "Collecting tqdm==4.32.1 (from -r requirements.txt (line 19))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/af/685bf3ce889ea191f3b916557f5677cc95a5e87b2fa120d74b5dd6d049d0/tqdm-4.32.1-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 26.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 20)) (0.0)\n",
            "Collecting soupsieve>=1.2 (from beautifulsoup4==4.7.1->-r requirements.txt (line 1))\n",
            "  Downloading https://files.pythonhosted.org/packages/35/e3/25079e8911085ab76a6f2facae0771078260c930216ab0b0c44dc5c9bf31/soupsieve-1.9.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.3.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.6.1)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.4.2->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (5.5.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (5.2.2)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (4.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter==1.0.0->-r requirements.txt (line 4)) (6.0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.0.1->-r requirements.txt (line 6)) (2.5.3)\n",
            "Requirement already satisfied: llvmlite>=0.28.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba==0.43.1->-r requirements.txt (line 8)) (0.29.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->-r requirements.txt (line 10)) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->-r requirements.txt (line 12)) (2019.6.16)\n",
            "Requirement already satisfied: Jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (2.10.1)\n",
            "Requirement already satisfied: Pygments>=1.6 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (2.1.3)\n",
            "Requirement already satisfied: pyzmq>=14.1.0 in /usr/local/lib/python3.6/dist-packages (from runipy==0.1.5->-r requirements.txt (line 13)) (17.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (1.0.2)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.0.1)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (7.0.4)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.2.2)\n",
            "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (2.6.0)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->-r requirements.txt (line 16)) (0.9.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tika==1.19->-r requirements.txt (line 18)) (41.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->-r requirements.txt (line 20)) (0.21.2)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.4.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (5.2.4)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel>=4.5.1->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.5.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (4.7.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (1.0.16)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 4)) (0.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7.2->runipy==0.1.5->-r requirements.txt (line 13)) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 20)) (0.13.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.4.2->-r requirements.txt (line 3)) (0.1.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Building wheels for collected packages: future, runipy, sqlalchemy, tika\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/61/d2/d6b7317325828fbb39ee6ad559dbe4664d0896da4721bf379e\n",
            "  Building wheel for runipy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/80/04/b2dbcd5df8afdb529918d2021094048a5917b6e76a6f7b452d\n",
            "  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/02/e3/7f1149be63131cdf6aaaa3330924a2683bb530188940569d66\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/db/8a/3a3f0c0725448eaa92703e3dda71e29dc13a119ff6c1036848\n",
            "Successfully built future runipy sqlalchemy tika\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: soupsieve, beautifulsoup4, future, lxml, numpy, matplotlib, numba, py4j, requests, runipy, scipy, sqlalchemy, tika, tqdm\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Found existing installation: numpy 1.16.4\n",
            "    Uninstalling numpy-1.16.4:\n",
            "      Successfully uninstalled numpy-1.16.4\n",
            "  Found existing installation: matplotlib 3.0.3\n",
            "    Uninstalling matplotlib-3.0.3:\n",
            "      Successfully uninstalled matplotlib-3.0.3\n",
            "  Found existing installation: numba 0.40.1\n",
            "    Uninstalling numba-0.40.1:\n",
            "      Successfully uninstalled numba-0.40.1\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: scipy 1.3.0\n",
            "    Uninstalling scipy-1.3.0:\n",
            "      Successfully uninstalled scipy-1.3.0\n",
            "  Found existing installation: SQLAlchemy 1.3.5\n",
            "    Uninstalling SQLAlchemy-1.3.5:\n",
            "      Successfully uninstalled SQLAlchemy-1.3.5\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed beautifulsoup4-4.7.1 future-0.17.1 lxml-4.3.3 matplotlib-3.0.1 numba-0.43.1 numpy-1.16.1 py4j-0.10.8.1 requests-2.22.0 runipy-0.1.5 scipy-1.2.1 soupsieve-1.9.2 sqlalchemy-1.3.3 tika-1.19 tqdm-4.32.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "requests",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/nishamuktewar/snorkel\n",
            "  Cloning https://github.com/nishamuktewar/snorkel to /tmp/pip-req-build-wo36ewn0\n",
            "  Running command git clone -q https://github.com/nishamuktewar/snorkel /tmp/pip-req-build-wo36ewn0\n",
            "Building wheels for collected packages: snorkel\n",
            "  Building wheel for snorkel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-65txfit4/wheels/1c/dc/7b/9cf55b0576fad8e74e4e4c004231d1fd2814b01915d5582ba2\n",
            "Successfully built snorkel\n",
            "Installing collected packages: snorkel\n",
            "Successfully installed snorkel-0.7.0b0\n",
            "Collecting treedlib\n",
            "  Downloading https://files.pythonhosted.org/packages/20/e8/dd387c84b91e6dd46f8c20ea94e58be2975eb9b80174edb4742441f3f82e/treedlib-0.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from treedlib) (4.3.3)\n",
            "Installing collected packages: treedlib\n",
            "Successfully installed treedlib-0.1.1\n",
            "Collecting numbskull\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/56/03f98485dec32d15522a59d35d87107a46375288a7a4ee1fffde7ff8fff2/numbskull-0.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from numbskull) (0.17.1)\n",
            "Installing collected packages: numbskull\n",
            "Successfully installed numbskull-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyPnpQ6t1-D-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnphVByC2D4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import sklearn\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prngmc0W2Fxy",
        "colab_type": "code",
        "outputId": "174e971b-c055-4711-eb08-e3f0bd940fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from snorkel import SnorkelSession\n",
        "from snorkel.models import candidate_subclass, Context, Candidate, StableLabel\n",
        "from snorkel.contrib.models.text import RawText\n",
        "from snorkel.annotations import LabelAnnotator\n",
        "from snorkel.learning import GenerativeModel\n",
        "from snorkel.annotations import save_marginals\n",
        "from snorkel.learning.tensorflow import TextRNN"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0629 16:40:17.874599 139910103627648 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2zUynbBUfV0",
        "colab_type": "text"
      },
      "source": [
        "### Download data if it doesn't exist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1TWYOoI2Tnj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2057a824-f25f-45cb-857a-bbe60387dda2"
      },
      "source": [
        "data_dir = \"./data\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "    !curl https://data.consumerfinance.gov/api/views/s6ew-h6mp/rows.csv?accessType=DOWNLOAD > ./data/complaints.csv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  722M    0  722M    0     0  8060k      0 --:--:--  0:01:31 --:--:-- 6153k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS5CHRYDUmfW",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing\n",
        "Data load, filtering out irrelevant fields and rows\n",
        "\n",
        "Selects two types of products, for example, credit reporting and mortgage. \n",
        "Returns dataframe with complaint, and label - 1 = credit reporting complaints, -1 = other (mortgage)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7govEII2gM3",
        "colab_type": "code",
        "outputId": "886ea58a-9094-4860-9084-16a67bf21cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "complaints = pd.read_csv(os.path.join(data_dir,'complaints.csv'))\n",
        "complaints.info()\n",
        "complaints.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (4,5,6,11,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1321470 entries, 0 to 1321469\n",
            "Data columns (total 18 columns):\n",
            "Date received                   1321470 non-null object\n",
            "Product                         1321470 non-null object\n",
            "Sub-product                     1086304 non-null object\n",
            "Issue                           1321470 non-null object\n",
            "Sub-issue                       785553 non-null object\n",
            "Consumer complaint narrative    392072 non-null object\n",
            "Company public response         469641 non-null object\n",
            "Company                         1321470 non-null object\n",
            "State                           1300745 non-null object\n",
            "ZIP code                        1200789 non-null object\n",
            "Tags                            180845 non-null object\n",
            "Consumer consent provided?      714364 non-null object\n",
            "Submitted via                   1321470 non-null object\n",
            "Date sent to company            1321470 non-null object\n",
            "Company response to consumer    1321463 non-null object\n",
            "Timely response?                1321470 non-null object\n",
            "Consumer disputed?              768501 non-null object\n",
            "Complaint ID                    1321470 non-null int64\n",
            "dtypes: int64(1), object(17)\n",
            "memory usage: 181.5+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1321470, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gwjyL9jUz48",
        "colab_type": "text"
      },
      "source": [
        "Subset data to include products with narrative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BcTLpTu2iV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "products_w_narrative = complaints[complaints['Product'].notnull() & \n",
        "                                  complaints['Consumer complaint narrative'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aswvj9bu2mJt",
        "colab_type": "code",
        "outputId": "c663a86b-97fb-42a6-cfad-02edd35a2919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "print(products_w_narrative['Product'].unique())\n",
        "print(products_w_narrative['Product'].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Credit reporting, credit repair services, or other personal consumer reports'\n",
            " 'Debt collection' 'Student loan' 'Credit card or prepaid card' 'Mortgage'\n",
            " 'Checking or savings account' 'Payday loan, title loan, or personal loan'\n",
            " 'Money transfer, virtual currency, or money service'\n",
            " 'Vehicle loan or lease' 'Credit card' 'Credit reporting'\n",
            " 'Bank account or service' 'Consumer Loan' 'Payday loan' 'Prepaid card'\n",
            " 'Money transfers' 'Other financial service' 'Virtual currency']\n",
            "Credit reporting, credit repair services, or other personal consumer reports    96097\n",
            "Debt collection                                                                 88419\n",
            "Mortgage                                                                        53689\n",
            "Credit reporting                                                                31588\n",
            "Credit card or prepaid card                                                     22274\n",
            "Student loan                                                                    22186\n",
            "Credit card                                                                     18838\n",
            "Bank account or service                                                         14885\n",
            "Checking or savings account                                                     13419\n",
            "Consumer Loan                                                                    9474\n",
            "Vehicle loan or lease                                                            5950\n",
            "Money transfer, virtual currency, or money service                               5647\n",
            "Payday loan, title loan, or personal loan                                        4604\n",
            "Payday loan                                                                      1747\n",
            "Money transfers                                                                  1497\n",
            "Prepaid card                                                                     1450\n",
            "Other financial service                                                           292\n",
            "Virtual currency                                                                   16\n",
            "Name: Product, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2MfDm0XU8H5",
        "colab_type": "text"
      },
      "source": [
        "Combine into one dataframe, create labels (1 for credit reporting, -1 for mortgage)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGAhdow-2oT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# credit reporting only\n",
        "credit_reporting = products_w_narrative[products_w_narrative['Product'] == 'Credit reporting, ' + \n",
        "                                 'credit repair services, or other personal consumer reports']\n",
        "# mortgage only\n",
        "mortgage = products_w_narrative[products_w_narrative['Product'] == 'Mortgage']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT9hYjQD2qvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "credit_narrative = credit_reporting['Consumer complaint narrative'].values\n",
        "positive_labels = pd.Series(np.ones(credit_narrative.shape[0]))\n",
        "positive_df = pd.DataFrame({'complaint': credit_narrative, 'label': positive_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev-bLnW02skW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mortgage_narrative = mortgage['Consumer complaint narrative'].values\n",
        "negative_labels = pd.Series(np.full(mortgage_narrative.shape[0], -1))\n",
        "negative_df = pd.DataFrame({'complaint': mortgage_narrative, 'label': negative_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZZP4-on2ukd",
        "colab_type": "code",
        "outputId": "d666dc21-5ae1-4cc6-83c1-643fde02f6bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "complaints_df = pd.concat([positive_df, negative_df], ignore_index=True)\n",
        "complaints_df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149786, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rX87qAw2wvc",
        "colab_type": "code",
        "outputId": "e9f8a279-93e5-4795-b5e5-8566fcc31eb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "complaints_df['label'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1.0    96097\n",
              "-1.0    53689\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2gAHJ0WVJU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#complaints_df = complaints_df.take(np.random.permutation(len(complaints_df))[:5000])\n",
        "#complaints_df['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rJlMTGxVDPE",
        "colab_type": "text"
      },
      "source": [
        "Split data into train, dev, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkY-5o7D2zFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, testval = train_test_split(complaints_df, test_size=0.2, random_state=123)\n",
        "dev, test = train_test_split(testval, test_size=0.5, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kv7_632VFL3",
        "colab_type": "text"
      },
      "source": [
        "### Create noisy labeling functions\n",
        "\n",
        "Regular expressions that define words, phrases, actions for use in labeling functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i70mzuQ421Hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "POSITIVE_WORDS = r'\\bcredit\\b|\\breport|\\baddress\\b|\\bcreditor\\b|\\bexperian\\b|\\btransunion\\b|\\bequifax\\b|\\bfcra\\b|\\bcollector\\b|\\bdebt\\b|\\bconsumer\\b'              \n",
        "POSITIVE_PHRASE = r\"\\bcredit (report|agency|reporting|bureau|agencies)\"\n",
        "NEGATIVE_WORDS = r'\\bloan\\b|\\bmortgage\\b|\\bhouse\\b|\\bhome\\b|\\bprepayment\\b|\\bappraise|\\bforeclos\\btax'\n",
        "POSITIVE_ACTIONS = r'\\bremov|\\bdispute\\b'\n",
        "NEGATIVE_ACTIONS = r'\\bpredator|\\bmodifi\\brefinanc'\n",
        "\n",
        "FRAUD = r'\\bfraudulent (account|charges)'\n",
        "MONEYXFER = r'\\bmoney transfer'\n",
        "CREDIT_REPORTING = r'\\b(identity has been compromise(|d)|data breaches|inquiries to businesses|mistakes appear in my report|reporting incorrectly|dispute(|d)|(t|T)ransunion|derogatory|experian|identity theft)'\n",
        "CREDIT_REPAIR = r'\\b(credit repair|hard inquiry|inquiries to businesses|mistakes appear in my report|reporting incorrectly)'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0a_eu1223tT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lf_credit(complaint):\n",
        "    if re.search(POSITIVE_WORDS, str(complaint), re.IGNORECASE):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def lf_credit_phrase(complaint):\n",
        "    if re.search(POSITIVE_PHRASE, str(complaint), re.IGNORECASE):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def lf_credit_actions(complaint):\n",
        "    if re.search(POSITIVE_ACTIONS, str(complaint), re.IGNORECASE):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def lf_mortgage(complaint):\n",
        "    if re.search(NEGATIVE_WORDS, str(complaint), re.IGNORECASE):\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def lf_mortgage_actions(complaint):\n",
        "    if re.search(NEGATIVE_ACTIONS, str(complaint), re.IGNORECASE):\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "def lf_fraud(complaint):\n",
        "    if (re.search(FRAUD, str(complaint), re.IGNORECASE)\n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)):\n",
        "        return 1\n",
        "    elif (re.search(FRAUD, str(complaint), re.IGNORECASE) \n",
        "          and re.search(MONEYXFER, str(complaint), re.IGNORECASE)):\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "def lf_reporting(complaint):\n",
        "    if (re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE) \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE)):\n",
        "        return 1\n",
        "    elif (re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE) \n",
        "           and re.search(MONEYXFER, str(complaint), re.IGNORECASE)):\n",
        "        return -1\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "def lf_repair(complaint):\n",
        "    if (re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE) \n",
        "        and not re.search(MONEYXFER, str(complaint), re.IGNORECASE) \n",
        "        and not re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE)\n",
        "       ):\n",
        "        return 1\n",
        "    elif ((re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE) \n",
        "           and re.search(MONEYXFER, str(complaint), re.IGNORECASE)) \n",
        "          or \n",
        "          (re.search(CREDIT_REPAIR, str(complaint), re.IGNORECASE) \n",
        "           and re.search(CREDIT_REPORTING, str(complaint), re.IGNORECASE))\n",
        "         ):\n",
        "        return -1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_pBGXxdVTKV",
        "colab_type": "text"
      },
      "source": [
        "### Generate Snorkel objects"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1GW0OCXVUJi",
        "colab_type": "text"
      },
      "source": [
        "#### Candidates\n",
        "\n",
        "Candidate objects in Snorkel represent objects to be classified. In this case we are interested in classifying whether a narrative is positive - credit related or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjVSxCjz26NK",
        "colab_type": "code",
        "outputId": "2506ee22-f36b-4ceb-8e0d-a801c3730d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "session = SnorkelSession()\n",
        "\n",
        "values = list(complaints_df.label.unique())\n",
        "print(values)\n",
        "\n",
        "# snorkel candidate, value if none defaults to binary (true, false)\n",
        "Narrative = candidate_subclass('Narrative', ['narrative'], values=values)\n",
        "\n",
        "# Make sure DB is cleared\n",
        "session.query(Context).delete()\n",
        "session.query(Candidate).delete()\n",
        "session.query(StableLabel).delete()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, -1.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcRDtTkoViEb",
        "colab_type": "text"
      },
      "source": [
        "#### Contexts\n",
        "\n",
        "All Candidate objects point to one or more Context objects represent the raw data that they are rooted in. In this case, our candidates will each point to a single Context object representing the raw text of the complaint.\n",
        "\n",
        "Once we have defined the Context for each Candidate, we can commit them to the database. Note that we also split into three sets while doing this:\n",
        "\n",
        "- Training set (split=0): The narratives for which we have noisy, conflicting labels from our labeling functions; we will resolve these conflicts using the GenerativeModel and then use them as training data for the RNN\n",
        "- Development set (split=1): We will pretend that we do not have any noisy, conflicting labels for this split of the data, and use these to test the RNN's performance on unseen data\n",
        "- Test set (split=2): We will pretend that we do not have any noisy, conflicting labels for this split of the data, and use these to test the RNN's performance on unseen data    \n",
        "\n",
        "Note: we also store the gold/ annotator labels available for future comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jypxk-b_3BAJ",
        "colab_type": "code",
        "outputId": "e0820b30-1c8f-4654-9eeb-288d372fea5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_index = train.index\n",
        "train.index.str = np.asarray(str(x) for x in train.index)\n",
        "train_complaints = train.values[:, 0]\n",
        "train_labels = train.values[:, 1]\n",
        "\n",
        "for element in zip(train_index, train_complaints, train_labels):\n",
        "    split = 0\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "    context_stable_id = \"~~\".join([str(element[0]), str(element[0])])\n",
        "    session.add(StableLabel(context_stable_ids=context_stable_id, \n",
        "                            annotator_name='gold',\n",
        "                            split=0,\n",
        "                            value=element[2]))\n",
        "dev_index = dev.index\n",
        "dev.index.str = np.asarray(str(x) for x in dev.index)\n",
        "dev_complaints = dev.values[:, 0]\n",
        "dev_labels = dev.values[:, 1]\n",
        "\n",
        "for element in zip(dev_index, dev_complaints, dev_labels):\n",
        "    split = 1\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "    context_stable_id = \"~~\".join([str(element[0]), str(element[0])])\n",
        "    session.add(StableLabel(context_stable_ids=context_stable_id, \n",
        "                            annotator_name='gold',\n",
        "                            split=1,\n",
        "                            value=element[2]))\n",
        "\n",
        "test_index = test.index\n",
        "test.index.str = np.asarray(str(x) for x in test.index)\n",
        "test_complaints = test.values[:, 0]\n",
        "test_labels = test.values[:, 1]\n",
        "\n",
        "for element in zip(test_index, test_complaints, test_labels):\n",
        "    split = 2\n",
        "    raw_text = RawText(stable_id=element[0], name=element[0], text=str(element[1]))\n",
        "    narrative = Narrative(narrative=raw_text, split=split)\n",
        "    session.add(narrative)\n",
        "    context_stable_id = \"~~\".join([str(element[0]), str(element[0])])\n",
        "    session.add(StableLabel(context_stable_ids=context_stable_id, \n",
        "                            annotator_name='gold',\n",
        "                            split=2,\n",
        "                            value=element[2]))\n",
        "\n",
        "session.commit()\n",
        "\n",
        "# number of datapoints\n",
        "print(session.query(Narrative).count())\n",
        "# load ground truth labels\n",
        "train_cand_labels = train_labels\n",
        "dev_cand_labels = dev_labels\n",
        "test_cand_labels = test_labels"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "149786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8--icqpq3JuM",
        "colab_type": "code",
        "outputId": "b653d642-ada5-4211-982d-8fd5bc0b0981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# test one labeling function\n",
        "labeled = []\n",
        "for c in session.query(Narrative).filter(Narrative.split == 1).all():\n",
        "    if lf_credit(c) != 0:\n",
        "        labeled.append(c)\n",
        "print(\"Number labeled:\", len(labeled))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number labeled: 11270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpOVOJiKVoSn",
        "colab_type": "text"
      },
      "source": [
        "#### Labels\n",
        "\n",
        "Next, we assign labeling functions for each of the training candidates in a sparse matrix (which will also automatically be saved to the Snorkel database), with one row for each candidate and one column for each label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQnhzeaf3nrt",
        "colab_type": "code",
        "outputId": "a80466ef-e3b9-4e75-f11e-e8e588d888ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "LFs = [lf_credit, lf_credit_phrase, lf_credit_actions, lf_mortgage, lf_mortgage_actions, lf_fraud, lf_reporting, lf_repair]\n",
        "# apply labeling functions\n",
        "labeler = LabelAnnotator(lfs = LFs)\n",
        "L_train = labeler.apply(split=0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 27/119828 [00:00<07:30, 266.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n",
            "Running UDF...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 119828/119828 [06:55<00:00, 288.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCtH_AV-3scM",
        "colab_type": "code",
        "outputId": "0cf0e90b-3e8e-447b-f6c1-79711ecdf8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# see what's going on\n",
        "print(L_train.get_candidate(session, 0))\n",
        "print(L_train.get_key(session, 0))\n",
        "print(L_train.lf_stats(session))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Narrative(Raw Text Today, XX/XX/XXXX, I noted an abnormal charge ( from Experian ) on my bank account for {$21.00}. I called the number associated with the transaction and was advised that on XX/XX/XXXX, I signed up for a 7-day trial credit-monitoring service for {$1.00} which would turn into a recurring {$21.00} monthly charge if I failed to cancel the service before the end of the 7-day trial period. \n",
            "\n",
            "I honestly don't remember signing up for this service ; I do, however, remember paying {$1.00} to view my credit score when I requested my credit reports from all three credit agencies ( via XXXX ) at the beginning of the year. Is Experian not required to give me more information surrounding my alleged subscription for this service and the terms I allegedly agreed to? \n",
            "\n",
            "I have been charged for this credit-monitoring service for the last five months. During the last five months, I have received zero monthly statements for this bill and zero receipts of payment from Experian. The service representative I spoke to claimed that I should have been aware of these charges because they were showing up in my bank statements. \n",
            "\n",
            "Are businesses allowed to pull money, on a recurring basis, from a bank account without notifying the owner of the account? That people are assumed to review their bank account statements is no justification for the business ' failure to provide monthly statements or receipts. XXXX and XXXX are just two of the companies that take recurring payments from my bank account and still have the courtesy of providing me with monthly statements and/or receipts. Is that what notice of a monthly recurring fee is - a courtesy and not one required by any consumer protection statute or regulation?)\n",
            "LabelKey (lf_credit)\n",
            "                     j  Coverage  Overlaps  Conflicts\n",
            "lf_credit            0  0.752854  0.675994   0.273676\n",
            "lf_credit_phrase     1  0.439129  0.439129   0.128993\n",
            "lf_credit_actions    2  0.329906  0.323889   0.099451\n",
            "lf_mortgage          3  0.454769  0.281337   0.276997\n",
            "lf_mortgage_actions  4  0.011742  0.011625   0.007285\n",
            "lf_fraud             5  0.020913  0.020563   0.003238\n",
            "lf_reporting         6  0.324824  0.321861   0.087267\n",
            "lf_repair            7  0.028049  0.027456   0.018935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6CcudVdVvxk",
        "colab_type": "text"
      },
      "source": [
        "### Training generative model\n",
        "\n",
        "Check if it assumes that the LFs have no dependencies by default?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bbo3wzLj5ukd",
        "colab_type": "code",
        "outputId": "11b921f1-8173-4798-c156-2f5c661c8b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gen_model = GenerativeModel()\n",
        "gen_model.train(L_train, epochs=20, decay=0.95, step_size=0.1/L_train.shape[0], reg_param=1e-6)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inferred cardinality: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XgNEwhsV31e",
        "colab_type": "text"
      },
      "source": [
        "### Applying the generative model\n",
        "\n",
        "#### Probabilistic Label Statistics\n",
        "We view the distribution of weak labels produced by our generative model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-pU4eS5_Na",
        "colab_type": "code",
        "outputId": "89953bce-5599-45ff-af50-448cc88a0808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "train_marginals = gen_model.marginals(L_train)\n",
        "plt.hist(train_marginals, bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdSWOLOHV8xM",
        "colab_type": "text"
      },
      "source": [
        "### Compare learned accuracies vs empirical accuracies\n",
        "Learned accuracies from our generative model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu6pQmGf8a60",
        "colab_type": "code",
        "outputId": "f3d01c2e-0b80-4081-93ab-a4ea35e86a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy = gen_model.score(L_train, train_cand_labels)\n",
        "accuracy[0]\n",
        "print(\"precision: {:.5f}\".format(accuracy[0]), \"recall: {:.5f}\".format(accuracy[1]), \n",
        "      \"F-beta: {:.5f}\".format(accuracy[2]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.64936 recall: 0.96852 F-beta: 0.77746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAHOrwAi8wia",
        "colab_type": "code",
        "outputId": "566667b1-70bc-42ac-9d72-85d02b3420b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Collect the majority vote answer for each complaint\n",
        "mv = []\n",
        "for i in range(L_train.shape[0]):\n",
        "    if np.diff(L_train[i].indptr) != 0:   #indicates that there is no coverage for a particular datapoint\n",
        "        c = Counter([L_train[i,j] for j in L_train[i].nonzero()[1]])\n",
        "        #print(c)\n",
        "        mv.append(c.most_common(1)[0][0])\n",
        "        #print(c.most_common(1)[0][0])\n",
        "    else:\n",
        "        mv.append(-1) # assume that no label is equivalent to a negative example\n",
        "\n",
        "mv = np.array(mv)\n",
        "\n",
        "# Count the number correct by majority vote\n",
        "n_correct = np.sum([1 for i in range(L_train.shape[0]) if mv[i] == train_cand_labels[i]])\n",
        "print (\"Accuracy:{}\".format(n_correct / float(L_train.shape[0])))\n",
        "print (\"Number incorrect:{}\".format(L_train.shape[0] - n_correct))\n",
        "\n",
        "# Compute and return precision, recall, and F1 score\n",
        "tp = (0.5 * (mv * train_cand_labels + 1))[mv == 1].sum()\n",
        "pred_pos = mv[mv == 1].sum()\n",
        "p = tp / float(pred_pos) if pred_pos > 0 else 0.0\n",
        "pos = train_cand_labels[train_cand_labels == 1].sum()\n",
        "r = tp / float(pos) if pos > 0 else 0.0\n",
        "\n",
        "# Compute general F-beta score\n",
        "beta=1\n",
        "if p + r > 0:\n",
        "    f_beta = (1 + beta**2) * ((p * r) / (((beta**2) * p) + r))\n",
        "else:\n",
        "    f_beta = 0.0\n",
        "p, r, f_beta\n",
        "print(\"precision: {:.5f}\".format(p), \"recall: {:.5f}\".format(r), \"F-beta: {:.5f}\".format(f_beta))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:0.8155356010281404\n",
            "Number incorrect:22104\n",
            "precision: 0.79390 recall: 0.96223 F-beta: 0.87000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot9U8G1jWEjO",
        "colab_type": "text"
      },
      "source": [
        "We can also get a more detailed score (true positives, false positives, true negatives, false negatives) on the dev set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFUbHlys9M4x",
        "colab_type": "code",
        "outputId": "ae0b21d9-67a3-45d5-afef-2786d3cc2ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "L_dev = labeler.apply(split=1)\n",
        "# score it\n",
        "tp, fp, tn, fn = gen_model.error_analysis(session, L_dev, dev_cand_labels)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clearing existing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 31/14979 [00:00<00:49, 303.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running UDF...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14979/14979 [00:51<00:00, 291.89it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Scores (Un-adjusted)\n",
            "========================================\n",
            "Pos. class accuracy: 0.967\n",
            "Neg. class accuracy: 0.0629\n",
            "Precision            0.645\n",
            "Recall               0.967\n",
            "F1                   0.774\n",
            "----------------------------------------\n",
            "TP: 9233 | FP: 5091 | TN: 342 | FN: 313\n",
            "========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1w-dKHZ8TMF",
        "colab_type": "text"
      },
      "source": [
        "Save the predictions of the generative model on the train and test set back to the database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yNNLBQ89vVZ",
        "colab_type": "code",
        "outputId": "9f6af032-d622-434b-a137-0a757ee41ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "save_marginals(session, L_train, train_marginals)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved 119828 marginals\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEUbvftvWOII",
        "colab_type": "text"
      },
      "source": [
        "### Training a ML model based on the probabilistic labels\n",
        "\n",
        "First, load the candidates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO3eCdQp924i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cands = session.query(Narrative).filter(Narrative.split == 0).order_by(Narrative.id).all()\n",
        "dev_cands   = session.query(Narrative).filter(Narrative.split == 1).order_by(Narrative.id).all()\n",
        "test_cands  = session.query(Narrative).filter(Narrative.split == 2).order_by(Narrative.id).all()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSAjjnerWX6U",
        "colab_type": "text"
      },
      "source": [
        "Note how the number of training samples are lower than what's present in the training set, it excludes samples where there was no LF coverage (train_marginals.shape[0] - (train_marginals == 0.5).sum())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvoqgKfq932D",
        "colab_type": "code",
        "outputId": "7871a257-0546-4854-da67-af98e7acd8ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "train_kwargs = {\n",
        "    'lr':         0.001,\n",
        "    'dim':        200,\n",
        "    'n_epochs':   20,\n",
        "    'dropout':    0.2,\n",
        "    'print_freq': 1,\n",
        "    'seed': 123,\n",
        "    'batch_size': 200,\n",
        "    'max_sentence_length': 500,\n",
        "    'vocab_size': 200\n",
        "}\n",
        "\n",
        "lstm = TextRNN(seed=123, cardinality=Narrative.cardinality)\n",
        "# Note: Y_train are the marginals but Y_dev are the gold/ ground truth labels\n",
        "lstm.train(X_train=train_cands, Y_train=train_marginals, X_dev=dev_cands, Y_dev=dev_cand_labels, **train_kwargs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0629 16:59:57.848574 139910103627648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/snorkel/learning/tensorflow/noise_aware_model.py:114: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "W0629 16:59:57.850262 139910103627648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/snorkel/learning/tensorflow/rnn/rnn_base.py:74: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0629 16:59:57.858996 139910103627648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/snorkel/learning/tensorflow/rnn/rnn_base.py:83: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "W0629 16:59:57.883962 139910103627648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/snorkel/learning/tensorflow/rnn/rnn_base.py:90: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0629 16:59:57.884899 139910103627648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/snorkel/learning/tensorflow/rnn/rnn_base.py:92: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "W0629 16:59:57.912288 139910103627648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/snorkel/learning/tensorflow/rnn/rnn_base.py:110: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "W0629 16:59:57.913327 139910103627648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "max sentence len in training data:  5729\n",
            "but capped to:  500\n",
            "And also curtailing warning(s) related to checking individual max sentence lengths in each narrative\n",
            "currrent vocab size is:  169560\n",
            "but capped to:  200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0629 16:59:58.025889 139910103627648 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:738: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0629 16:59:58.367947 139910103627648 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:244: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0629 16:59:58.513574 139910103627648 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/snorkel/learning/tensorflow/rnn/rnn_base.py:117: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0629 16:59:58.536861 139910103627648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/snorkel/learning/tensorflow/noise_aware_model.py:126: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0629 16:59:59.744559 139910103627648 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/snorkel/learning/tensorflow/noise_aware_model.py:89: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[TextRNN] Training model\n",
            "[TextRNN] n_train=115179  #epochs=20  batch size=200\n",
            "[TextRNN] Epoch 0 (498.61s)\tAverage loss=0.311905\tDev F1=77.85\n",
            "[TextRNN] Epoch 1 (1021.51s)\tAverage loss=0.310351\tDev F1=77.85\n",
            "[TextRNN] Epoch 2 (1543.62s)\tAverage loss=0.282915\tDev F1=77.85\n",
            "[TextRNN] Epoch 3 (2066.77s)\tAverage loss=0.279703\tDev F1=77.85\n",
            "[TextRNN] Epoch 4 (2589.51s)\tAverage loss=0.277743\tDev F1=77.85\n",
            "[TextRNN] Epoch 5 (3108.95s)\tAverage loss=0.276681\tDev F1=77.85\n",
            "[TextRNN] Epoch 6 (3628.54s)\tAverage loss=0.293467\tDev F1=77.84\n",
            "[TextRNN] Epoch 7 (4147.77s)\tAverage loss=0.286906\tDev F1=77.85\n",
            "[TextRNN] Epoch 8 (4665.95s)\tAverage loss=0.282406\tDev F1=77.85\n",
            "[TextRNN] Epoch 9 (5184.49s)\tAverage loss=0.280227\tDev F1=77.85\n",
            "[TextRNN] Epoch 10 (5702.60s)\tAverage loss=0.279259\tDev F1=77.85\n",
            "[TextRNN] Epoch 11 (6219.97s)\tAverage loss=0.278339\tDev F1=77.85\n",
            "[TextRNN] Epoch 12 (6738.89s)\tAverage loss=0.277385\tDev F1=77.85\n",
            "[TextRNN] Epoch 13 (7260.70s)\tAverage loss=0.276593\tDev F1=77.86\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-wA6gEfWhl1",
        "colab_type": "text"
      },
      "source": [
        "#### Accuracies on dev and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZBYLyyW-LdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_dev = lstm.score(dev_cands, dev_cand_labels, batch_size=200)\n",
        "print(\"precision: {:.5f}\".format(accuracy_dev[0]), \"recall: {:.5f}\".format(accuracy_dev[1]), \n",
        "      \"F-beta: {:.5f}\".format(accuracy_dev[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlC3vfgA-Nse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_test = lstm.score(test_cands, test_cand_labels, batch_size=200)\n",
        "print(\"precision: {:.5f}\".format(accuracy_test[0]), \"recall: {:.5f}\".format(accuracy_test[1]), \n",
        "      \"F-beta: {:.5f}\".format(accuracy_test[2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8LdSPjCpbZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert df back to csv, with column names\n",
        "train[\"train_marginals\"] = train_marginals\n",
        "train.to_csv(data_dir+'/train.csv', index=False)\n",
        "test.to_csv(data_dir+'/test.csv', index=False)\n",
        "dev.to_csv(data_dir+'/dev.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}